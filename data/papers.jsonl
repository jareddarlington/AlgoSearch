{"title": "Using Non-Linear Difference Equations to Study Quicksort Algorithms", "authors": ["Yukun Yao"], "published": "2019-04-30T22:04:28Z", "updated": "2020-02-26T02:21:40Z", "abstract": "Using non-linear difference equations, combined with symbolic computations, we make a detailed study of the running times of numerous variants of the celebrated Quicksort algorithms, where we consider the variants of single-pivot and multi-pivot Quicksort algorithms as discrete probability problems. With non-linear difference equations, recurrence relations and experimental mathematics techniques, explicit expressions for expectations, variances and even higher moments of their numbers of comparisons and swaps can be obtained. For some variants, Monte Carlo experiments are performed, the numerical results are demonstrated and the scaled limiting distribution is also discussed.", "categories": ["cs.DS", "math.CO"], "id": "1905.00118v3", "status": "failed", "error": "Paper contains no well-defined algorithm environments"}
{"title": "Inventory Routing Problem with Facility Location", "authors": ["Yang Jiao", "R. Ravi"], "published": "2019-05-01T01:04:02Z", "updated": "2019-05-01T01:04:02Z", "abstract": "We study problems that integrate depot location decisions along with the inventory routing problem of serving clients from these depots over time balancing the costs of routing vehicles from the depots with the holding costs of demand delivered before they are due. Since the inventory routing problem is already complex, we study the version that assumes that the daily vehicle routes are direct connections from the depot thus forming stars as solutions, and call this problem the Star Inventory Routing Problem with Facility Location (SIRPFL). As a stepping stone to solving SIRPFL, we first study the Inventory Access Problem (IAP), which is the single depot, single client special case of IRP. The Uncapacitated IAP is known to have a polynomial time dynamic program. We provide an NP-hardness reduction for Capacitated IAP where each demand cannot be split among different trips. We give a $3$-approximation for the case when demands can be split and a $6$-approximation for the unsplittable case. For Uncapacitated SIRPFL, we provide a $12$-approximation by rounding an LP relaxation. Combining the ideas from Capacitated IAP and Uncapacitated SIRPFL, we obtain a $24$-approximation for Capacitated Splittable SIRPFL and a $48$-approximation for the most general version, the Capacitated Unsplittable SIRPFL.", "categories": ["cs.DS"], "id": "1905.00148v1", "status": "success", "error": null}
{"title": "Variable Neighborhood Search for the Bin Packing Problem with Compatible Categories", "authors": ["Luiz F. O. Moura Santos", "Hugo T. Y. Yoshizaki", "Claudio B. Cunha"], "published": "2019-05-09T03:14:15Z", "updated": "2019-05-09T03:14:15Z", "abstract": "Bin Packing with Conflicts (BPC) are problems in which items with compatibility constraints must be packed in the least number of bins, not exceeding the capacity of the bins and ensuring that non-conflicting items are packed in each bin. In this work, we introduce the Bin Packing Problem with Compatible Categories (BPCC), a variant of the BPC in which items belong to conflicting or compatible categories, in opposition to the item-by-item incompatibility found in previous literature. It is a common problem in the context of last mile distribution to nanostores located in densely populated areas. To efficiently solve real-life sized instances of the problem, we propose a Variable Neighborhood Search (VNS) metaheuristic algorithm. Computational experiments suggest that the algorithm yields good solutions in very short times while compared to linear integer programming running on a high-performance computing environment.", "categories": ["cs.DS", "cs.AI", "math.OC"], "id": "1905.03427v1", "status": "failed", "error": "Source not available (received application/pdf)"}
{"title": "Testing Bipartitness in an Augmented VDF Bounded-Degree Graph Model", "authors": ["Oded Goldreich"], "published": "2019-05-08T13:48:13Z", "updated": "2019-06-05T11:57:02Z", "abstract": "In a recent work (ECCC, TR18-171, 2018), we introduced models of testing graph properties in which, in addition to answers to the usual graph-queries, the tester obtains {\\em random vertices drawn according to an arbitrary distribution $D$}. Such a tester is required to distinguish between graphs that have the property and graphs that are far from having the property, {\\em where the distance between graphs is defined based on the unknown vertex distribution $D$}. These (\"vertex-distribution free\" (VDF)) models generalize the standard models in which $D$ is postulated to be uniform on the vertex-set, and they were studies both in the dense graph model and in the bounded-degree graph model.\n  The focus of the aforementioned work was on testers, called {\\sf strong}, whose query complexity depends only on the proximity parameter $\u03b5$. Unfortunately, in the standard bounded-degree graph model, some natural properties such as Bipartiteness do not have strong testers, and others (like cycle-freeness) do not have strong testers of one-sided error (whereas one-sided error was shown inherent to the VDF model). Hence, it was suggested to study general (i.e., non-strong) testers of \"sub-linear\" complexity.\n  In this work, we pursue the foregoing suggestion, but do so in a model that augments the model presented in the aforementioned work. Specifically, we provide the tester with an evaluation oracle to the unknown distribution $D$, in addition to samples of $D$ and oracle access to the tested graph. Our main results are testers for Bipartitness and cycle-freeness, in this augmented model, having complexity that is almost-linear in the square root of the \"effective support size\" of $D$.", "categories": ["cs.DS"], "id": "1905.03070v2", "status": "failed", "error": "Invalid or corrupted archive - source may not be available"}
{"title": "Efficient On-line Computation of Visibility Graphs", "authors": ["Delia Fano Yela", "Florian Thalmann", "Vincenzo Nicosia", "Dan Stowell", "Mark Sandler"], "published": "2019-05-08T16:44:09Z", "updated": "2019-05-08T16:44:09Z", "abstract": "A visibility algorithm maps time series into complex networks following a simple criterion. The resulting visibility graph has recently proven to be a powerful tool for time series analysis. However its straightforward computation is time-consuming and rigid, motivating the development of more efficient algorithms. Here we present a highly efficient method to compute visibility graphs with the further benefit of flexibility: on-line computation. We propose an encoder/decoder approach, with an on-line adjustable binary search tree codec for time series as well as its corresponding decoder for visibility graphs. The empirical evidence suggests the proposed method for computation of visibility graphs offers an on-line computation solution at no additional computation time cost. The source code is available online.", "categories": ["cs.DS"], "id": "1905.03204v1", "status": "failed", "error": "Paper contains no well-defined algorithm environments"}
{"title": "Orthogonal Range Reporting and Rectangle Stabbing for Fat Rectangles", "authors": ["Timothy M. Chan", "Yakov Nekrich", "Michiel Smid"], "published": "2019-05-07T02:08:05Z", "updated": "2019-05-07T02:08:05Z", "abstract": "In this paper we study two geometric data structure problems in the special case when input objects or queries are fat rectangles. We show that in this case a significant improvement compared to the general case can be achieved.\n  We describe data structures that answer two- and three-dimensional orthogonal range reporting queries in the case when the query range is a \\emph{fat} rectangle. Our two-dimensional data structure uses $O(n)$ words and supports queries in $O(\\log\\log U +k)$ time, where $n$ is the number of points in the data structure, $U$ is the size of the universe and $k$ is the number of points in the query range. Our three-dimensional data structure needs $O(n\\log^{\\varepsilon}U)$ words of space and answers queries in $O(\\log \\log U + k)$ time. We also consider the rectangle stabbing problem on a set of three-dimensional fat rectangles. Our data structure uses $O(n)$ space and answers stabbing queries in $O(\\log U\\log\\log U +k)$ time.", "categories": ["cs.DS"], "id": "1905.02322v1", "status": "failed", "error": "Paper contains no well-defined algorithm environments"}
{"title": "Authenticated Key-Value Stores with Hardware Enclaves", "authors": ["Yuzhe Tang", "Ju Chen", "Kai Li", "Jianliang Xu", "Qi Zhang"], "published": "2019-04-26T22:45:04Z", "updated": "2019-11-06T23:38:02Z", "abstract": "Authenticated data storage on an untrusted platform is an important computing paradigm for cloud applications ranging from big-data outsourcing, to cryptocurrency and certificate transparency log. These modern applications increasingly feature update-intensive workloads, whereas existing authenticated data structures (ADSs) designed with in-place updates are inefficient to handle such workloads. In this paper, we address this issue and propose a novel authenticated log-structured merge tree (eLSM) based key-value store by leveraging Intel SGX enclaves.\n  We present a system design that runs the code of eLSM store inside enclave. To circumvent the limited enclave memory (128 MB with the latest Intel CPUs), we propose to place the memory buffer of the eLSM store outside the enclave and protect the buffer using a new authenticated data structure by digesting individual LSM-tree levels. We design protocols to support query authentication in data integrity, completeness (under range queries), and freshness. The proof in our protocol is made small by including only the Merkle proofs at selective levels.\n  We implement eLSM on top of Google LevelDB and Facebook RocksDB with minimal code change and performance interference. We evaluate the performance of eLSM under the YCSB workload benchmark and show a performance advantage of up to 4.5X speedup.", "categories": ["cs.CR", "cs.DB", "cs.DC", "cs.DS"], "id": "1904.12068v3", "status": "failed", "error": "Paper contains no well-defined algorithm environments"}
{"title": "Fast Commutative Matrix Algorithm", "authors": ["Andreas Rosowski"], "published": "2019-04-16T14:05:49Z", "updated": "2020-07-27T06:22:54Z", "abstract": "We show that the product of an nx3 matrix and a 3x3 matrix over a commutative ring can be computed using 6n+3 multiplications. For two 3x3 matrices this gives us an algorithm using 21 multiplications. This is an improvement with respect to Makarov's algorithm using 22 multiplications[13]. We generalize our result for nx3 and 3x3 matrices and present an algorithm for computing the product of an lxn matrix and an nxm matrix over a commutative ring for odd n using n(lm+l+m-1)/2 multiplications if m is odd and using (n(lm+l+m-1)+l-1)/2 multiplications if m is even. Waksman's and Islam's algorithm for odd n needs (n-1)(lm+l+m-1)/2+lm multiplications [10,19], thus in both cases less multiplications are required by our algorithm. We also give an algorithm for even n using n(lm+l+m-1)/2 multiplications without making use of divisions, since Waksman's and Islam's algorithm make use of some divisions by 2 [10,19]. Furthermore we present a novelty for matrix multiplication: In this paper we show that some non-bilinear algorithms with special properties can be used as recursive algorithms. In comparison to bilinear algorithms for small nxn matrices say n<20 we obtain some better results. From these non-bilinear algorithms we finally obtain approximate non-bilinear algorithms. For instance we obtain an approximate non-bilinear algorithm for 5x5 matrices that uses only 89 multiplications. If at all it is possible to compare this algorithm with a bilinear algorithm we obtain a better result with respect to Smirnov's algorithm [15].", "categories": ["cs.CC", "cs.DS"], "id": "1904.07683v2", "status": "failed", "error": "Invalid or corrupted archive - source may not be available"}
{"title": "Independent Set Reconfiguration Parameterized by Modular-Width", "authors": ["R\u00e9my Belmonte", "Tesshu Hanaka", "Michael Lampis", "Hirotaka Ono", "Yota Otachi"], "published": "2019-05-01T14:58:11Z", "updated": "2019-05-01T14:58:11Z", "abstract": "Independent Set Reconfiguration is one of the most well-studied problems in the setting of combinatorial reconfiguration. It is known that the problem is PSPACE-complete even for graphs of bounded bandwidth. This fact rules out the tractability of parameterizations by most well-studied structural parameters as most of them generalize bandwidth. In this paper, we study the parameterization by modular-width, which is not comparable with bandwidth. We show that the problem parameterized by modular-width is fixed-parameter tractable under all previously studied rules TAR, TJ, and TS. The result under TAR resolves an open problem posed by Bonsma [WG 2014, JGT 2016].", "categories": ["cs.DS"], "id": "1905.00340v1", "status": "failed", "error": "Paper contains no well-defined algorithm environments"}
{"title": "Accurate MapReduce Algorithms for $k$-median and $k$-means in General Metric Spaces", "authors": ["Alessio Mazzetto", "Andrea Pietracaprina", "Geppino Pucci"], "published": "2019-04-29T14:12:15Z", "updated": "2019-09-29T19:58:38Z", "abstract": "Center-based clustering is a fundamental primitive for data analysis and becomes very challenging for large datasets. In this paper, we focus on the popular $k$-median and $k$-means variants which, given a set $P$ of points from a metric space and a parameter $k<|P|$, require to identify a set $S$ of $k$ centers minimizing, respectively, the sum of the distances and of the squared distances of all points in $P$ from their closest centers. Our specific focus is on general metric spaces, for which it is reasonable to require that the centers belong to the input set (i.e., $S \\subseteq P$). We present coreset-based 3-round distributed approximation algorithms for the above problems using the MapReduce computational model. The algorithms are rather simple and obliviously adapt to the intrinsic complexity of the dataset, captured by the doubling dimension $D$ of the metric space. Remarkably, the algorithms attain approximation ratios that can be made arbitrarily close to those achievable by the best known polynomial-time sequential approximations, and they are very space efficient for small $D$, requiring local memory sizes substantially sublinear in the input size. To the best of our knowledge, no previous distributed approaches were able to attain similar quality-performance guarantees in general metric spaces.", "categories": ["cs.DC", "cs.DS"], "id": "1904.12728v2", "status": "success", "error": null}
{"title": "On Romeo and Juliet Problems: Minimizing Distance-to-Sight", "authors": ["Hee-Kap Ahn", "Eunjin Oh", "Lena Schlipf", "Fabian Stehn", "Darren Strash"], "published": "2019-06-03T22:47:57Z", "updated": "2019-06-03T22:47:57Z", "abstract": "We introduce a variant of the watchman route problem, which we call the quickest pair-visibility problem. Given two persons standing at points $s$ and $t$ in a simple polygon $P$ with no holes, we want to minimize the distance they travel in order to see each other in $P$. We solve two variants of this problem, one minimizing the longer distance the two persons travel (min-max) and one minimizing the total travel distance (min-sum), optimally in linear time. We also consider a query version of this problem for the min-max variant. We can preprocess a simple $n$-gon in linear time so that the minimum of the longer distance the two persons travel can be computed in $O(\\log^2 n)$ time for any two query positions $s,t$ where the two persons start.", "categories": ["cs.CG", "cs.DS"], "id": "1906.01114v1", "status": "failed", "error": "Paper contains no well-defined algorithm environments"}
{"title": "A Direct $\\tilde{O}(1/\u03b5)$ Iteration Parallel Algorithm for Optimal Transport", "authors": ["Arun Jambulapati", "Aaron Sidford", "Kevin Tian"], "published": "2019-06-03T07:58:09Z", "updated": "2019-06-03T07:58:09Z", "abstract": "Optimal transportation, or computing the Wasserstein or ``earth mover's'' distance between two distributions, is a fundamental primitive which arises in many learning and statistical settings. We give an algorithm which solves this problem to additive $\u03b5$ with $\\tilde{O}(1/\u03b5)$ parallel depth, and $\\tilde{O}\\left(n^2/\u03b5\\right)$ work. Barring a breakthrough on a long-standing algorithmic open problem, this is optimal for first-order methods. Blanchet et. al. '18, Quanrud '19 obtained similar runtimes through reductions to positive linear programming and matrix scaling. However, these reduction-based algorithms use complicated subroutines which may be deemed impractical due to requiring solvers for second-order iterations (matrix scaling) or non-parallelizability (positive LP). The fastest practical algorithms run in time $\\tilde{O}(\\min(n^2 / \u03b5^2, n^{2.5} / \u03b5))$ (Dvurechensky et. al. '18, Lin et. al. '19). We bridge this gap by providing a parallel, first-order, $\\tilde{O}(1/\u03b5)$ iteration algorithm without worse dependence on dimension, and provide preliminary experimental evidence that our algorithm may enjoy improved practical performance. We obtain this runtime via a primal-dual extragradient method, motivated by recent theoretical improvements to maximum flow (Sherman '17).", "categories": ["cs.DS", "cs.LG", "math.OC", "stat.CO", "stat.ML"], "id": "1906.00618v1", "status": "success", "error": null}
{"title": "Near-Perfect Recovery in the One-Dimensional Latent Space Model", "authors": ["Yu Chen", "Sampath Kannan", "Sanjeev Khanna"], "published": "2020-06-08T04:49:41Z", "updated": "2020-06-08T04:49:41Z", "abstract": "Suppose a graph $G$ is stochastically created by uniformly sampling vertices along a line segment and connecting each pair of vertices with a probability that is a known decreasing function of their distance. We ask if it is possible to reconstruct the actual positions of the vertices in $G$ by only observing the generated unlabeled graph. We study this question for two natural edge probability functions -- one where the probability of an edge decays exponentially with the distance and another where this probability decays only linearly. We initiate our study with the weaker goal of recovering only the order in which vertices appear on the line segment. For a segment of length $n$ and a precision parameter $\u03b4$, we show that for both exponential and linear decay edge probability functions, there is an efficient algorithm that correctly recovers (up to reflection symmetry) the order of all vertices that are at least $\u03b4$ apart, using only $\\tilde{O}(\\frac{n}{\u03b4^ 2})$ samples (vertices). Building on this result, we then show that $O(\\frac{n^2 \\log n}{\u03b4^2})$ vertices (samples) are sufficient to additionally recover the location of each vertex on the line to within a precision of $\u03b4$. We complement this result with an $\u03a9(\\frac{n^{1.5}}\u03b4)$ lower bound on samples needed for reconstructing positions (even by a computationally unbounded algorithm), showing that the task of recovering positions is information-theoretically harder than recovering the order. We give experimental results showing that our algorithm recovers the positions of almost all points with high accuracy.", "categories": ["cs.DS"], "id": "2006.04351v1", "status": "success", "error": null}
{"title": "A Survey on Approximation in Parameterized Complexity: Hardness and Algorithms", "authors": ["Andreas Emil Feldmann", "Karthik C. S.", "Euiwoong Lee", "Pasin Manurangsi"], "published": "2020-06-08T08:34:47Z", "updated": "2020-06-08T08:34:47Z", "abstract": "Parameterization and approximation are two popular ways of coping with NP-hard problems. More recently, the two have also been combined to derive many interesting results. We survey developments in the area both from the algorithmic and hardness perspectives, with emphasis on new techniques and potential future research directions.", "categories": ["cs.DS", "cs.CC"], "id": "2006.04411v1", "status": "failed", "error": "Paper contains no well-defined algorithm environments"}
{"title": "Better and Simpler Learning-Augmented Online Caching", "authors": ["Alexander Wei"], "published": "2020-05-28T00:32:52Z", "updated": "2020-05-28T00:32:52Z", "abstract": "Lykouris and Vassilvitskii (ICML 2018) introduce a model of online caching with machine-learned advice, where each page request additionally comes with a prediction of when that page will next be requested. In this model, a natural goal is to design algorithms that (1) perform well when the advice is accurate and (2) remain robust in the worst case a la traditional competitive analysis. Lykouris and Vassilvitskii give such an algorithm by adapting the Marker algorithm to the learning-augmented setting. In a recent work, Rohatgi (SODA 2020) improves on their result with an approach also inspired by randomized marking. We continue the study of this problem, but with a somewhat different approach: We consider combining the BlindOracle algorithm, which just na\u00efvely follows the predictions, with an optimal competitive algorithm for online caching in a black-box manner. The resulting algorithm outperforms all existing approaches while being significantly simpler. Moreover, we show that combining BlindOracle with LRU is in fact optimal among deterministic algorithms for this problem.", "categories": ["cs.DS"], "id": "2005.13716v1", "status": "failed", "error": "Paper contains no well-defined algorithm environments"}
{"title": "GeoTree: a data structure for constant time geospatial search enabling a real-time mix-adjusted median property price index", "authors": ["Robert Miller", "Phil Maguire"], "published": "2020-08-05T14:37:37Z", "updated": "2020-08-05T14:37:37Z", "abstract": "A common problem appearing across the field of data science is $k$-NN ($k$-nearest neighbours), particularly within the context of Geographic Information Systems. In this article, we present a novel data structure, the GeoTree, which holds a collection of geohashes (string encodings of GPS co-ordinates). This enables a constant $O\\left(1\\right)$ time search algorithm that returns a set of geohashes surrounding a given geohash in the GeoTree, representing the approximate $k$-nearest neighbours of that geohash. Furthermore, the GeoTree data structure retains $O\\left(n\\right)$ memory requirement. We apply the data structure to a property price index algorithm focused on price comparison with historical neighbouring sales, demonstrating an enhanced performance. The results show that this data structure allows for the development of a real-time property price index, and can be scaled to larger datasets with ease.", "categories": ["cs.DS"], "id": "2008.02167v1", "status": "failed", "error": "Paper contains no well-defined algorithm environments"}
{"title": "Hierarchical Clusterings of Unweighted Graphs", "authors": ["Svein H\u00f8gemo", "Christophe Paul", "Jan Arne Telle"], "published": "2020-08-07T09:45:46Z", "updated": "2020-08-07T09:45:46Z", "abstract": "We study the complexity of finding an optimal hierarchical clustering of an unweighted similarity graph under the recently introduced Dasgupta objective function. We introduce a proof technique, called the normalization procedure, that takes any such clustering of a graph $G$ and iteratively improves it until a desired target clustering of G is reached. We use this technique to show both a negative and a positive complexity result. Firstly, we show that in general the problem is NP-complete. Secondly, we consider min-well-behaved graphs, which are graphs $H$ having the property that for any $k$ the graph $H(k)$ being the join of $k$ copies of $H$ has an optimal hierarchical clustering that splits each copy of $H$ in the same optimal way. To optimally cluster such a graph $H(k)$ we thus only need to optimally cluster the smaller graph $H$. Co-bipartite graphs are min-well-behaved, but otherwise they seem to be scarce. We use the normalization procedure to show that also the cycle on 6 vertices is min-well-behaved.", "categories": ["cs.CC", "cs.DS", "math.CO"], "id": "2008.03061v1", "status": "success", "error": null}
{"title": "A simpler strong refutation of random $k$-XOR", "authors": ["Kwangjun Ahn"], "published": "2020-08-08T16:41:07Z", "updated": "2020-08-08T16:41:07Z", "abstract": "Strong refutation of random CSPs is a fundamental question in theoretical computer science that has received particular attention due to the long-standing gap between the information-theoretic limit and the computational limit. This gap is recently bridged by Raghavendra, Rao and Schramm where they study sub-exponential algorithms for the regime between the two limits. In this work, we take a simpler approach to their algorithm and analysis.", "categories": ["cs.DS"], "id": "2008.03556v1", "status": "failed", "error": "Paper contains no well-defined algorithm environments"}
{"title": "Performance analysis of a distributed algorithm for admission control in wireless networks under the $2$-hop interference model", "authors": ["Ashwin Ganesan"], "published": "2020-07-14T09:07:06Z", "updated": "2020-07-14T09:07:06Z", "abstract": "A general open problem in networking is: what are the fundamental limits to the performance that is achievable with some given amount of resources? More specifically, if each node in the network has information about only its $1$-hop neighborhood, then what are the limits to performance? This problem is considered for wireless networks where each communication link has a minimum bandwidth quality-of-service (QoS) requirement. Links in the same vicinity contend for the shared wireless medium. The conflict graph captures which pairs of links interfere with each other and depends on the MAC protocol. In IEEE 802.11 MAC protocol-based networks, when communication between nodes $i$ and $j$ takes place, the neighbors of both $i$ and $j$ remain silent. This model of interference is called the $2$-hop interference model because the distance in the network graph between any two links that can be simultaneously active is at least $2$. In the admission control problem, the objective is to determine, using only localized information, whether a given set of flow rates is feasible.\n  In the present work, a distributed algorithm is proposed for this problem, where each node has information only about its $1$-hop neighborhood. The worst-case performance of the distributed algorithm, i.e. the largest factor by which the performance of this distributed algorithm is away from that of an optimal, centralized algorithm, is analyzed. Lower and upper bounds on the suboptimality of the distributed algorithm are obtained, and both bounds are shown to be tight. The exact worst-case performance is obtained for some ring topologies. While distance-$d$ distributed algorithms have been analyzed for the $1$-hop interference model, an open problem in the literature is to extend these results to the $K$-hop interference model, and the present work initiates the generalization to the $K$-hop interference model.", "categories": ["cs.IT", "cs.DS", "cs.NI"], "id": "2007.07921v1", "status": "failed", "error": "Paper contains no well-defined algorithm environments"}
{"title": "Optimal $\\ell_1$ Column Subset Selection and a Fast PTAS for Low Rank Approximation", "authors": ["Arvind V. Mahankali", "David P. Woodruff"], "published": "2020-07-20T17:50:30Z", "updated": "2020-11-16T07:22:43Z", "abstract": "We study the problem of entrywise $\\ell_1$ low rank approximation. We give the first polynomial time column subset selection-based $\\ell_1$ low rank approximation algorithm sampling $\\tilde{O}(k)$ columns and achieving an $\\tilde{O}(k^{1/2})$-approximation for any $k$, improving upon the previous best $\\tilde{O}(k)$-approximation and matching a prior lower bound for column subset selection-based $\\ell_1$-low rank approximation which holds for any $\\text{poly}(k)$ number of columns. We extend our results to obtain tight upper and lower bounds for column subset selection-based $\\ell_p$ low rank approximation for any $1 < p < 2$, closing a long line of work on this problem.\n  We next give a $(1 + \\varepsilon)$-approximation algorithm for entrywise $\\ell_p$ low rank approximation, for $1 \\leq p < 2$, that is not a column subset selection algorithm. First, we obtain an algorithm which, given a matrix $A \\in \\mathbb{R}^{n \\times d}$, returns a rank-$k$ matrix $\\hat{A}$ in $2^{\\text{poly}(k/\\varepsilon)} + \\text{poly}(nd)$ running time such that: $$\\|A - \\hat{A}\\|_p \\leq (1 + \\varepsilon) \\cdot OPT + \\frac{\\varepsilon}{\\text{poly}(k)}\\|A\\|_p$$ where $OPT = \\min_{A_k \\text{ rank }k} \\|A - A_k\\|_p$. Using this algorithm, in the same running time we give an algorithm which obtains error at most $(1 + \\varepsilon) \\cdot OPT$ and outputs a matrix of rank at most $3k$ -- these algorithms significantly improve upon all previous $(1 + \\varepsilon)$- and $O(1)$-approximation algorithms for the $\\ell_p$ low rank approximation problem, which required at least $n^{\\text{poly}(k/\\varepsilon)}$ or $n^{\\text{poly}(k)}$ running time, and either required strong bit complexity assumptions (our algorithms do not) or had bicriteria rank $3k$. Finally, we show hardness results which nearly match our $2^{\\text{poly}(k)} + \\text{poly}(nd)$ running time and the above additive error guarantee.", "categories": ["cs.DS", "cs.LG", "stat.ML"], "id": "2007.10307v2", "status": "failed", "error": "Invalid or corrupted archive - source may not be available"}
